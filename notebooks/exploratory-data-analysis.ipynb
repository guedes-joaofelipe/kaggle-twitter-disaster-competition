{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = \"data/preprocess\"\n",
    "# nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"./../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (6090, 14)\n",
      "Valid set: (1523, 14)\n",
      "Test set: (3263, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>profile_tags</th>\n",
       "      <th>hash_tags</th>\n",
       "      <th>link_tags</th>\n",
       "      <th>n_profile_tags</th>\n",
       "      <th>n_hash_tags</th>\n",
       "      <th>n_link_tags</th>\n",
       "      <th>exclamation_count</th>\n",
       "      <th>question_count</th>\n",
       "      <th>location_ner</th>\n",
       "      <th>with_location</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7025</th>\n",
       "      <td>mayhem</td>\n",
       "      <td>Manavadar, Gujarat</td>\n",
       "      <td>They are the real heroes... RIP Brave hearts.....</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'3rd Eye Chakra': None, '@symbolicjensen': No...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4689</th>\n",
       "      <td>engulfed</td>\n",
       "      <td>USA</td>\n",
       "      <td>Car engulfed in flames backs up traffic at Par...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'3rd Eye Chakra': None, '@symbolicjensen': No...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>collapsed</td>\n",
       "      <td>Alexandria, Egypt.</td>\n",
       "      <td>Great British Bake Off's back and Dorret's cho...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'3rd Eye Chakra': None, '@symbolicjensen': No...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>destroyed</td>\n",
       "      <td>USA</td>\n",
       "      <td>Black Eye 9: A space battle occurred at Star O...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'3rd Eye Chakra': None, '@symbolicjensen': No...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3924</th>\n",
       "      <td>devastated</td>\n",
       "      <td>Dorset, UK</td>\n",
       "      <td>???????????? @MikeParrActor absolutely devasta...</td>\n",
       "      <td>0</td>\n",
       "      <td>[@MikeParrActor]</td>\n",
       "      <td>[#RossBarton]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>{'3rd Eye Chakra': None, '@symbolicjensen': No...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         keyword            location  \\\n",
       "id                                     \n",
       "7025      mayhem  Manavadar, Gujarat   \n",
       "4689    engulfed                 USA   \n",
       "2388   collapsed  Alexandria, Egypt.   \n",
       "3742   destroyed                 USA   \n",
       "3924  devastated          Dorset, UK   \n",
       "\n",
       "                                                   text  target  \\\n",
       "id                                                                \n",
       "7025  They are the real heroes... RIP Brave hearts.....       0   \n",
       "4689  Car engulfed in flames backs up traffic at Par...       1   \n",
       "2388  Great British Bake Off's back and Dorret's cho...       1   \n",
       "3742  Black Eye 9: A space battle occurred at Star O...       0   \n",
       "3924  ???????????? @MikeParrActor absolutely devasta...       0   \n",
       "\n",
       "          profile_tags      hash_tags link_tags  n_profile_tags  n_hash_tags  \\\n",
       "id                                                                             \n",
       "7025                []             []        []               0            0   \n",
       "4689                []             []        []               0            0   \n",
       "2388                []             []        []               0            0   \n",
       "3742                []             []        []               0            0   \n",
       "3924  [@MikeParrActor]  [#RossBarton]        []               1            1   \n",
       "\n",
       "      n_link_tags  exclamation_count  question_count  \\\n",
       "id                                                     \n",
       "7025            0                  0               0   \n",
       "4689            0                  0               0   \n",
       "2388            0                  0               0   \n",
       "3742            0                  0               0   \n",
       "3924            0                  0              12   \n",
       "\n",
       "                                           location_ner  with_location  \n",
       "id                                                                      \n",
       "7025  {'3rd Eye Chakra': None, '@symbolicjensen': No...              0  \n",
       "4689  {'3rd Eye Chakra': None, '@symbolicjensen': No...              0  \n",
       "2388  {'3rd Eye Chakra': None, '@symbolicjensen': No...              0  \n",
       "3742  {'3rd Eye Chakra': None, '@symbolicjensen': No...              0  \n",
       "3924  {'3rd Eye Chakra': None, '@symbolicjensen': No...              1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_parquet(os.path.join(DATA_PATH, \"train.parquet\"))\n",
    "df_valid = pd.read_parquet(os.path.join(DATA_PATH, \"valid.parquet\"))\n",
    "df_test = pd.read_parquet(os.path.join(DATA_PATH, \"test.parquet\"))\n",
    "\n",
    "print (\"Train set:\", df_train.shape)\n",
    "print (\"Valid set:\", df_valid.shape)\n",
    "print (\"Test set:\", df_test.shape)\n",
    "\n",
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3456\n",
       "1    2634\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    text = re.sub(f\"'[a-z]\", \"\", text)\n",
    "    text = re.sub(f\"[{string.punctuation}]\", \"\", text)\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    text = \" \".join(tokens)\n",
    "\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"text_\"] = df_train[\"text\"].apply(clean_text)\n",
    "df_valid[\"text_\"] = df_valid[\"text\"].apply(clean_text)\n",
    "df_test[\"text_\"] = df_test[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from numpy.random import RandomState\n",
    "from typing import Union\n",
    "\n",
    "class TfIdfEmbedding(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, column=\"text_clean\") -> None:\n",
    "        super().__init__()\n",
    "        self.column = column\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X[self.column].values\n",
    "\n",
    "        self.vectorizer.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return self.vectorizer.transform(X).toarray()\n",
    "\n",
    "\n",
    "# Embedding = TfIdfEmbedding\n",
    "# embedding = Embedding()\n",
    "# embedding.fit(X[\"text_\"])\n",
    "# embeddings = embedding.transform(X[\"text_\"])\n",
    "# embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['keyword', 'location', 'text', 'target', 'profile_tags', 'hash_tags',\n",
       "       'link_tags', 'n_profile_tags', 'n_hash_tags', 'n_link_tags',\n",
       "       'exclamation_count', 'question_count', 'location_ner', 'with_location',\n",
       "       'text_'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('text_transformer',\n",
       "                                                  TfIdfEmbedding(), ['text_']),\n",
       "                                                 ('num_transformer',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['n_profile_tags',\n",
       "                                                   'n_hash_tags', 'n_link_tags',\n",
       "                                                   'exclamation_count',\n",
       "                                                   'question_count',\n",
       "                                                   'with_location'])])),\n",
       "                ('model', LogisticRegressionClassifier(max_iter=1000))])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from src.models.utils import get_model\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "Model = get_model(\"LogisticRegressionClassifier\")\n",
    "X = df_train[[\"text_\"]]\n",
    "y = df_train[[\"target\"]]\n",
    "\n",
    "class TfIdfEmbedding(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values.ravel()\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.vectorizer.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values.ravel()\n",
    "\n",
    "        X = self.vectorizer.transform(X)\n",
    "\n",
    "        return X.toarray()\n",
    "\n",
    "text_transformer = TfIdfEmbedding()\n",
    "num_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"text_transformer\", text_transformer, [\"text_\"]),\n",
    "        (\"num_transformer\", num_transformer, ['n_profile_tags', 'n_hash_tags', 'n_link_tags', 'exclamation_count', 'question_count', 'with_location'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            # (\"decomposition\", TruncatedSVD(n_components=50)),\n",
    "            (\"model\", Model(max_iter=1000)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "pipeline.fit(df_train.drop(columns=[\"target\"]), df_train[\"target\"])\n",
    "# pipeline.fit_transform(df_train.head(500).drop(columns=[\"target\"]), df_train.head(500)[\"target\"])\n",
    "# pipeline.predict(df_train[\"text_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83       886\n",
      "           1       0.81      0.66      0.73       637\n",
      "\n",
      "    accuracy                           0.79      1523\n",
      "   macro avg       0.80      0.77      0.78      1523\n",
      "weighted avg       0.79      0.79      0.79      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true = df_valid[\"target\"]\n",
    "y_pred = pipeline.predict(df_valid.drop(columns=[\"target\"]))\n",
    "\n",
    "print (classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.feature_extraction.text.CountVectorizer"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TfidfVectorizer.__base__\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
